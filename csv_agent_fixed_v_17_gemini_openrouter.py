import os
import zipfile
import pandas as pd
import streamlit as st
from pathlib import Path
# from langchain.llms import Ollama
# from langchain_ollama import OllamaLLM  # Removido: n√£o usamos mais Ollama
import requests
import tempfile
import shutil
import traceback
import locale
import re
import ast
import textwrap

# --- Cliente LLM via OpenRouter ---
class OpenRouterLLM:
    def __init__(self, model: str, api_key: str = None, temperature: float = 0.0):
        self.endpoint = "https://openrouter.ai/api/v1/chat/completions"
        self.model = model
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        self.temperature = temperature
        if not self.api_key:
            raise ValueError("Chave OPENROUTER_API_KEY n√£o encontrada no ambiente.")

    def invoke(self, prompt: str) -> str:
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": self.temperature
        }
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        resp = requests.post(self.endpoint, json=payload, headers=headers)
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]


def main():
    st.set_page_config(
        page_title="Agente de An√°lise CSV",
        page_icon="üìä",
        layout="wide"
    )

class CSVAnalysisAgent:
    def __init__(self):
        """Inicializa o agente com LLM via OpenRouter"""
        try:
            self.llm = OpenRouterLLM(
                model="openrouter/deepseek-chat-v3-0324:free",
                api_key=os.getenv("OPENROUTER_API_KEY"),
                temperature=0.0
            )
        except Exception as e:
            st.error(f"Erro ao inicializar LLM: {e}")
            st.info("Configure a vari√°vel de ambiente OPENROUTER_API_KEY com seu token.")
            return
        self.dataframes = {}
        self.current_df = None

    def extract_zip_files(self, zip_path, extract_to):
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_to)
            return True
        except Exception as e:
            st.error(f"Erro ao descompactar: {e}")
            return False

    def load_csv_files(self, directory):
        csv_files = {}
        for file_path in Path(directory).rglob("*.csv"):
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                df.columns = df.columns.str.strip()
                csv_files[file_path.name] = df
                st.success(f"Carregado: {file_path.name} ({len(df)} linhas)")
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(file_path, encoding='latin-1')
                    df.columns = df.columns.str.strip()
                    csv_files[file_path.name] = df
                    st.success(f"Carregado: {file_path.name} ({len(df)} linhas)")
                except Exception as e:
                    st.error(f"Erro ao carregar {file_path.name}: {e}")
            except Exception as e:
                st.error(f"Erro ao carregar {file_path.name}: {e}")
        return csv_files

    def select_dataframe(self, df_name):
        if df_name in self.dataframes:
            self.current_df = self.dataframes[df_name]
            return True
        return False

    def _query_llm(self, prompt: str) -> str:
        return self.llm.invoke(prompt)

    def step0_select_file(self, question):
        # l√≥gica inalterada, exceto chamada para invoke
        files_summary = """
ARQUIVOS DISPON√çVEIS:
1. '202401_NFs_Cabecalho.csv' ...
2. '202401_NFs_Itens.csv' ...
"""
        prompt = f"""
...PERGUNTA: "{question}"\n"""
        try:
            response = self._query_llm(prompt)
            # processa resposta...
        except Exception as e:
            return {'sucesso': False, 'erro': str(e)}

    def step1_interpret_question(self, question, selected_files):
        # substitua todas as chamadas self.llm.invoke(...) por self._query_llm(...)
        if len(selected_files) == 1:
            self.select_dataframe(selected_files[0])
            prompt = f"""
Seu prompt mestre para 1 arquivo...
PERGUNTA: "{question}"""  # mantenha template
        else:
            prompt = f"""
Seu prompt mestre para m√∫ltiplos arquivos...
PERGUNTA: "{question}"""
        response = self._query_llm(prompt)
        # limpa response e retorna c√≥digo

    def step2_execute_code(self, generated_code, selected_files):
        # id√™ntico ao original
        namespace = {'pd': pd, 'resultado': None}
        # adiciona dataframes...
        try:
            exec(generated_code, namespace)
            return {'sucesso': True, 'resultado': namespace.get('resultado'), 'codigo_executado': generated_code}
        except Exception as e:
            return {'sucesso': False, 'erro': str(e), 'traceback': traceback.format_exc()}

    def step3_generate_response(self, user_question, execution_result):
        # troca chamadas de self.llm.invoke para self._query_llm
        if execution_result['sucesso']:
            formatted_result = execution_result['resultado']
            prompt = f"""
Sua tarefa: gerar frase em pt de dados: {formatted_result}"""
        else:
            prompt = f"Erro: {execution_result['erro']}"
        return self._query_llm(prompt)

    def query_data(self, question):
        # fluxo principal, use self._query_llm em todo lugar
        ...

    # demais m√©todos inalterados

if __name__ == "__main__":
    st.sidebar.markdown("PR√â-REQUISITOS: pip install requests ...")
    def main():   
       st.title("ü§ñ Agente Inteligente para An√°lise de CSV")
    st.markdown("### üîÑ Sistema em 3 Etapas: Pergunta ‚Üí C√≥digo ‚Üí Execu√ß√£o ‚Üí Resposta")
    
        # Inicializa o agente
 if 'agent' not in st.session_state:
            st.session_state.agent = CSVAnalysisAgent()
    
        agent = st.session_state.agent
    
     # Sidebar para upload e configura√ß√£o
with st.sidebar:
            st.header("üìÅ Carregar Dados")
        
            # Upload de arquivo
            uploaded_file = st.file_uploader(
                "Fa√ßa upload de arquivo ZIP ou CSV",
                type=['zip', 'csv'],
                help="Aceita arquivos ZIP contendo CSVs ou arquivos CSV individuais"
            )
        
            if uploaded_file:
                # Cria diret√≥rio tempor√°rio
                temp_dir = tempfile.mkdtemp()
            
                try:
                    if uploaded_file.name.endswith('.zip'):
                        # Salva arquivo ZIP
                        zip_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(zip_path, 'wb') as f:
                            f.write(uploaded_file.getbuffer())
                    
                        # Descompacta
                        extract_dir = os.path.join(temp_dir, 'extracted')
                        if agent.extract_zip_files(zip_path, extract_dir):
                            # Carrega CSVs
                            agent.dataframes = agent.load_csv_files(extract_dir)
                    else:
                        # Arquivo CSV individual
                        csv_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(csv_path, 'wb') as f:
                            f.write(uploaded_file.getbuffer())
                        agent.dataframes = agent.load_csv_files(temp_dir)
                
                    st.success(f"Carregados {len(agent.dataframes)} arquivo(s) CSV")
                
                except Exception as e:
                    st.error(f"Erro ao processar arquivo: {e}")
    
        # Interface principal
        if agent.dataframes:
            col1, col2 = st.columns([1, 2])
        
            with col1:
                st.header("üìã Arquivos Dispon√≠veis")
            
                # Sele√ß√£o de arquivo
                selected_file = st.selectbox(
                    "Escolha um arquivo para analisar:",
                    list(agent.dataframes.keys())
                )
            
                if selected_file:
                    agent.select_dataframe(selected_file)
                
                    # Mostra informa√ß√µes do arquivo
                    with st.expander("‚ÑπÔ∏è Informa√ß√µes do Arquivo"):
                        info = agent.get_dataframe_info(selected_file)
                        stats = agent.get_quick_stats(selected_file)
                    
                        st.write(f"**Dimens√µes:** {info['shape'][0]} linhas √ó {info['shape'][1]} colunas")
                        st.write(f"**Linhas totais:** {stats['total_rows']}")
                        st.write(f"**Colunas num√©ricas:** {stats['numeric_columns']}")
                        st.write(f"**Colunas de texto:** {stats['text_columns']}")
                        st.write(f"**Valores nulos:** {stats['null_values']}")
                        st.write(f"**Linhas duplicadas:** {stats['duplicated_rows']}")
                    
                        st.write("**Colunas:**")
                        for col in info['columns']:
                            st.write(f"- {col}")
                
                    # An√°lise das colunas para debug
                    with st.expander("üîç An√°lise das Colunas"):
                        col_analysis = agent.get_column_analysis(selected_file)
                        if col_analysis:
                        for col, details in col_analysis.items():
                            st.write(f"**{col}:**")
                            st.write(f"  - Tipo: {details['tipo']}")
                            st.write(f"  - Valores √∫nicos: {details['valores_unicos']}")
                            st.write(f"  - Nulos: {details['nulos']}")
                            st.write(f"  - Exemplo: {details['exemplo']}")
                            st.write("---")
                
                    # Preview dos dados
                    with st.expander("üëÄ Preview dos Dados (5 primeiras linhas)"):
                        st.dataframe(agent.current_df.head())
                        st.caption(f"Mostrando 5 de {len(agent.current_df)} linhas totais")
        
            with col2:
                st.header("üí¨ Fa√ßa sua Pergunta")
            
                # Estat√≠sticas r√°pidas
                if selected_file:
                    stats = agent.get_quick_stats(selected_file)
                    st.info(f"üìä **Dataset atual:** {stats['total_rows']} linhas √ó {stats['total_columns']} colunas")
            
                # Alerta sobre corre√ß√£o
                st.info("üí° **Corre√ß√£o aplicada:** Sistema otimizado para usar valores reais do dataset!")
            
                # Explica√ß√£o do processo
                st.markdown("""
                **üîÑ Como funciona:**
                1. **Interpreta√ß√£o:** LLM entende sua pergunta e gera c√≥digo Python
                2. **Execu√ß√£o:** C√≥digo √© executado no dataset real
                3. **Resposta:** LLM transforma o resultado em resposta clara
                """)
            
                # Exemplos de perguntas
                st.write("**Exemplos de perguntas:**")
                examples = [
                    "Quantas linhas tem o dataset?",
                    "Qual produto tem o maior valor unit√°rio?",
                    "Qual fornecedor teve maior montante recebido?",
                    "Qual item teve maior volume entregue?",
                    "Mostre o top 5 produtos por quantidade",
                    "Qual a soma total dos valores?",
                    "Quantos fornecedores √∫nicos existem?"
                ]
            
                for example in examples:
                    if st.button(example, key=f"ex_{example}"):
                       st.session_state.question = example
            
                # Input da pergunta
                question = st.text_area(
                    "Sua pergunta:",
                    value=st.session_state.get('question', ''),
                    height=100,
                    placeholder="Digite sua pergunta sobre os dados..."
                )
                if st.button("üîç Analisar", type="primary"):
                    if question:
                        with st.spinner("ü§ñ Agente pensando... (Etapas 0 a 3)"):
                            response = agent.query_data(question)
                            st.success("‚úÖ Resposta Final do Agente:")
                            st.write(response)
                    else:
                        st.warning("Por favor, digite uma pergunta.")
    
        else:
            st.info("üëÜ Fa√ßa upload de um arquivo CSV ou ZIP contendo CSVs para come√ßar")
        
            # Instru√ß√µes
            with st.expander("üìñ Como usar"):
                st.write("""
                **Sistema em 3 Etapas:**
            
                1. **üìù Pergunta:** Voc√™ faz uma pergunta em linguagem natural
                2. **üß† Interpreta√ß√£o:** LLM analisa e gera c√≥digo Python espec√≠fico
                3. **‚ö° Execu√ß√£o:** C√≥digo √© executado no dataset real
                4. **üí¨ Resposta:** LLM transforma o resultado em resposta clara
            
                **Vantagens desta abordagem:**
                - ‚úÖ Maior precis√£o nas respostas
                - ‚úÖ Transpar√™ncia total (voc√™ v√™ o c√≥digo gerado)
                - ‚úÖ Menos erros de parsing
                - ‚úÖ Resultados baseados nos dados reais
            
                **Exemplos de perguntas suportadas:**
                - Quantas linhas tem o dataset?
                - Qual √© o maior valor na coluna X?
                - Mostre estat√≠sticas descritivas
                - Qual categoria tem mais itens?
                - Some os valores da coluna Y
                """)

    # Configura√ß√£o para executar
    if __name__ == "__main__":
        # Instru√ß√µes de instala√ß√£o
        st.sidebar.markdown("""
        ### üõ†Ô∏è Pr√©-requisitos
    
        **Instalar depend√™ncias:**
        ```bash
        pip install streamlit langchain pandas
        ```
        """)
    main()
